{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils_data\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\") as inputf:\n",
    "    text = inputf.read()\n",
    "    \n",
    "text = text.replace('<start>', '$')\n",
    "text = text.replace('<end>', '%')\n",
    "    \n",
    "count_chars = Counter(text)\n",
    "num_chars = len(count_chars)\n",
    "    \n",
    "#one hot encoding\n",
    "char_to_int = {word:idx for idx,word in enumerate(count_chars.keys())}\n",
    "int_to_char = {idx:word for idx,word in enumerate(count_chars.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoader(random_seed, data_dir, seq_length, batchsize = 16, use_cuda = False, shuffle=True):\n",
    "    \n",
    "    with open(data_dir) as inputf:\n",
    "        text = inputf.read()\n",
    "    \n",
    "    text = text.replace('<start>', '$')\n",
    "    text = text.replace('<end>', '%')\n",
    "    \n",
    "    count_chars = Counter(text)\n",
    "    num_chars = len(count_chars)\n",
    "    \n",
    "    #one hot encoding\n",
    "    char_to_int = {word:idx for idx,word in enumerate(count_chars.keys())}\n",
    "    int_to_char = {idx:word for idx,word in enumerate(count_chars.keys())}\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "    temp_input = []\n",
    "    temp_label = []\n",
    "    \n",
    "    for i, c in enumerate(text, 0):\n",
    "        one_hot_encoding = torch.zeros((1, num_chars))\n",
    "        one_hot_encoding[0, char_to_int[c]] = 1\n",
    "        temp_input.append(one_hot_encoding)\n",
    "        temp_label.append(char_to_int[c])\n",
    "        if i % seq_length == seq_length - 1:\n",
    "            inputs.append(torch.cat(temp_input, 0))\n",
    "            labels.append(torch.LongTensor(temp_label))\n",
    "            temp_input = []\n",
    "            temp_label = []\n",
    "    \n",
    "    inputs, labels = torch.stack(inputs, 0), torch.stack(labels, 0)\n",
    "    \n",
    "    dataset = utils_data.TensorDataset(inputs, labels)\n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    indices = np.arange(dataset_size)\n",
    "    \n",
    "    split = int(dataset_size * 0.2)\n",
    "    \n",
    "    train_inds = indices[: -split]\n",
    "    valid_inds = indices[-split:]\n",
    "    \n",
    "    if shuffle:\n",
    "        trainsampler = torch.utils.data.sampler.SubsetRandomSampler(train_inds)\n",
    "        validsampler = torch.utils.data.sampler.SubsetRandomSampler(valid_inds)\n",
    "    else:\n",
    "        trainsampler = torch.utils.data.sampler.SequentialSampler(train_inds)\n",
    "        validsampler = torch.utils.data.sampler.SequentialSampler(valid_inds)\n",
    "    \n",
    "    if use_cuda:\n",
    "        pin_memory = True\n",
    "    else:\n",
    "        pin_memory = False\n",
    "\n",
    "    training_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchsize, \n",
    "                                                      num_workers = 4, sampler = trainsampler, \n",
    "                                                      pin_memory = pin_memory)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchsize,\n",
    "                                                  num_workers = 4, sampler = validsampler, \n",
    "                                                  pin_memory = pin_memory)\n",
    "\n",
    "    dataloaders = [training_dataloader, valid_dataloader]\n",
    "    \n",
    "    print ('data loaded.')\n",
    "    \n",
    "    return dataloaders, num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, criterion, optimizer, epochs, dataloaders, step_size = None, \n",
    "             gamma = None, early_stop = False, use_cuda = False, checkpoint_ind = 1, \n",
    "             model_dir = None, best_model = False, shuffle = True):\n",
    "    \n",
    "    '''\n",
    "    function that trains and save/load the model\n",
    "    args:\n",
    "            criterion: loss function\n",
    "            epochs: # of epochs to iterate\n",
    "            dataloaders: list of torch.utils.data.DataLoader, the first element must be \n",
    "                         dataloader for training set\n",
    "            step_size: if None, then no learning rate decay is applied; \n",
    "                       if an integer, learning rate decays for every step_size epochs;\n",
    "                       if a list, learning rate decays at specific epochs given in list\n",
    "            gamma: decay ratio for learning rate at each time of decay\n",
    "            early_stop: if True, training will stop if validation loss rises consistently \n",
    "                        for 6 epochs (the second element in dataloaders will be regarded \n",
    "                        as the dataloader for validation set as default)\n",
    "            use_cuda: if True, model will be trained with .cuda()\n",
    "            model_dir: if not None, it will try to load pre-saved model in 'model_dir' and \n",
    "                       resume the training (including optimizer and learning rate scheduler)\n",
    "            best_model: if True, it will try to load pre-saved best model in 'model_dir' \n",
    "                        and resume the training (including optimizer and learning rate \n",
    "                        scheduler)\n",
    "    \n",
    "    return:\n",
    "            statlists: a list containing statistics during training\n",
    "                       len(statlists) is equal to len(dataloaders)\n",
    "    '''\n",
    "    \n",
    "    print ('start training...')\n",
    "    \n",
    "    from_scratch = True\n",
    "    \n",
    "    if model_dir is not None:\n",
    "        # load model saved early and resume training\n",
    "        if best_model:\n",
    "            model_dir = model_dir + '/' + 'best_' + model.__class__.__name__ + '_ckpt' + str(checkpoint_ind) + '.pth.tar'\n",
    "        else:\n",
    "            model_dir = model_dir + '/' + model.__class__.__name__ + '_ckpt' + str(checkpoint_ind) + '.pth.tar'\n",
    "        if os.path.isfile(model_dir):\n",
    "            print (\"loading checkpoint '{}'\".format(model_dir))\n",
    "            from_scratch = False\n",
    "            checkpoint = torch.load(model_dir)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            statlists = checkpoint['stats']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print (\"loaded checkpoint '{}' (epoch {})\".format(model_dir, checkpoint['epoch']))\n",
    "            if isinstance(step_size, int):\n",
    "                scheduler = lr_scheduler.StepLR(optimizer = optimizer, step_size = step_size, \n",
    "                                                gamma = gamma, last_epoch = (start_epoch - 1))\n",
    "            elif isinstance(step_size, list):\n",
    "                scheduler = lr_scheduler.MultiStepLR(optimizer = optimizer, milestones = step_size, \n",
    "                                                gamma = gamma, last_epoch = (start_epoch - 1))\n",
    "            min_valid_loss = np.min(statlists[1])\n",
    "        else:\n",
    "            print (\"no checkpoint found at '{}'.\".format(model_dir), 'training from scratch.')\n",
    "    \n",
    "    # only if the model_dir is given, and such a model does exist, we will not training from scratch\n",
    "    if from_scratch:\n",
    "        # training from scratch\n",
    "        start_epoch = 1\n",
    "        statlists = [[] for _ in np.arange(len(dataloaders))]\n",
    "        if isinstance(step_size, int):\n",
    "            scheduler = lr_scheduler.StepLR(optimizer = optimizer, step_size = step_size, \n",
    "                                            gamma = gamma)\n",
    "        elif isinstance(step_size, list):\n",
    "            scheduler = lr_scheduler.MultiStepLR(optimizer = optimizer, milestones = step_size, \n",
    "                                            gamma = gamma)\n",
    "        min_valid_loss = 10e6\n",
    "    \n",
    "    \n",
    "    stop = 0\n",
    "    filename = model.__class__.__name__ + '_ckpt' + str(checkpoint_ind)\n",
    "    \n",
    "    # training iteration\n",
    "    for epoch in np.arange(start_epoch, epochs + 1):\n",
    "    \n",
    "        if not use_cuda:\n",
    "            avg_loss = 0.0\n",
    "            \n",
    "        if step_size is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        if not shuffle:\n",
    "                init_hidden = model.init_hidden()\n",
    "                if 'LSTM' in model.__class__.__name__:\n",
    "                    model.hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "                elif 'GRU' in model.__class__.__name__:\n",
    "                    model.hidden = init_hidden.cuda()\n",
    "\n",
    "        for i, data in enumerate(dataloaders[0], 0):\n",
    "            loss = 0\n",
    "            inputs, labels = data\n",
    "            if inputs.size(0) < model.batchsize:\n",
    "                break\n",
    "            inputs_len = len(inputs[0])\n",
    "            inputs, labels = inputs.permute(1, 0, 2)[: inputs_len - 1, :, :], labels[:, 1:]\n",
    "            # inputs: <class 'torch.FloatTensor'> torch.Size([sequence length, batchsize, 95]) \n",
    "            # labels: <class 'torch.LongTensor'> torch.Size([batchsize, ])  \n",
    "            if use_cuda:\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                if shuffle:\n",
    "                    init_hidden = model.init_hidden()\n",
    "                    if 'LSTM' in model.__class__.__name__:\n",
    "                        model.hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "                    elif 'GRU' in model.__class__.__name__:\n",
    "                        model.hidden = init_hidden.cuda()\n",
    "            else:\n",
    "                inputs = Variable(inputs)\n",
    "                labels = Variable(labels)\n",
    "                if shuffle:\n",
    "                    model.hidden = model.init_hidden()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "#             sys.exit(0)\n",
    "            for i in range(outputs.size(1)):\n",
    "                loss += criterion(outputs[:, i, :], labels[i, :])\n",
    "            loss = loss / model.batchsize\n",
    "            \n",
    "            if shuffle:\n",
    "                loss.backward()\n",
    "            else:\n",
    "                loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            if not use_cuda:\n",
    "                avg_loss += loss.data[0]\n",
    "\n",
    "                if i % 200 == 199:\n",
    "                    print('[%d, %5d] loss: %.3f' %(epoch, i + 1, avg_loss / 200))\n",
    "                    avg_loss = 0.0\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        # evaluate model after each epoch\n",
    "        if use_cuda:\n",
    "            if not shuffle:\n",
    "                init_hidden = model.init_hidden()\n",
    "                if 'LSTM' in model.__class__.__name__:\n",
    "                    model.hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "                elif 'GRU' in model.__class__.__name__:\n",
    "                        model.hidden = init_hidden.cuda()\n",
    "            for loader, statlist in zip(dataloaders, statlists):\n",
    "                totalloss = 0.0\n",
    "                batchs = 0\n",
    "                for data in loader:\n",
    "                    batchloss = 0\n",
    "                    inputs, labels = data\n",
    "                    if inputs.size(0) < model.batchsize:\n",
    "                        break\n",
    "                    inputs_len = len(inputs[0])\n",
    "                    inputs, labels = inputs.permute(1, 0, 2)[: inputs_len - 1, :, :], labels[:, 1:]\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                    if shuffle:\n",
    "                        init_hidden = model.init_hidden()\n",
    "                        if 'LSTM' in model.__class__.__name__:\n",
    "                            model.hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "                        elif 'GRU' in model.__class__.__name__:\n",
    "                            model.hidden = init_hidden.cuda()\n",
    "                    outputs = model(inputs)\n",
    "                    for i in range(outputs.size(1)):\n",
    "                        batchloss += criterion(outputs[:, i, :], labels[i, :]).data[0]\n",
    "                    totalloss += batchloss / model.batchsize\n",
    "                    batchs += 1\n",
    "\n",
    "                statlist.append(totalloss / batchs)\n",
    "            \n",
    "            print('epoch: %d       loss:' %epoch, end = '', flush = True)\n",
    "            for statlist in statlists:\n",
    "                print ('%.3f         ' %statlist[-1], end = '', flush = True)\n",
    "            print ('')\n",
    "            \n",
    "            if min_valid_loss > statlists[1][-1]:\n",
    "                is_best = True\n",
    "                min_valid_loss = statlists[1][-1]\n",
    "            else:\n",
    "                is_best = False\n",
    "            \n",
    "            # model will be saved for each 10 epochs, or if the current model obtains \n",
    "            # best performance so far.\n",
    "            if is_best or (epoch % 10 == 0):\n",
    "                save_checkpoint({'epoch': epoch + 1,\n",
    "                                'state_dict': model.state_dict(),\n",
    "                                'stats': statlists,\n",
    "                                'optimizer': optimizer.state_dict()\n",
    "                                }, is_best, filename)\n",
    "            \n",
    "        if early_stop and epoch >= 2:\n",
    "            if statlists[1][-1] >= statlists[1][-2]:\n",
    "                stop += 1\n",
    "            else:\n",
    "                stop = 0\n",
    "            \n",
    "            if stop >= 6:\n",
    "                print ('stop training due to rising validloss.')\n",
    "                save_checkpoint({'epoch': epoch + 1,\n",
    "                                'state_dict': model.state_dict(),\n",
    "                                'stats': statlists,\n",
    "                                'optimizer': optimizer.state_dict()\n",
    "                                }, False, filename)\n",
    "                break\n",
    "\n",
    "    print ('training finished.')\n",
    "    \n",
    "    return statlists\n",
    "    \n",
    "    \n",
    "# the save/load model code can be found at \n",
    "# https://github.com/pytorch/examples/blob/master/imagenet/main.py#L267\n",
    "def save_checkpoint(state, is_best, filename = 'checkpoint'):\n",
    "    path_name = './model/' + filename + '.pth.tar'\n",
    "    torch.save(state, path_name)\n",
    "    if is_best:\n",
    "        best_path = './model/' + 'best_' + filename + '.pth.tar'\n",
    "        shutil.copyfile(path_name, best_path)\n",
    "    print ('model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss):\n",
    "    '''\n",
    "    function for plotting loss\n",
    "    args:\n",
    "            loss: a list containing loss evaluated on each set of data after each epoch\n",
    "                  during training. \n",
    "                  loss[0] for training loss; loss[1] for validation loss; \n",
    "                  loss[2] for test loss.\n",
    "                  \n",
    "    '''\n",
    "    epoch_range = range(1, len(loss[0]) + 1)\n",
    "\n",
    "    plot1 = plt.plot(epoch_range, loss[0], 'r', linewidth = 1.4, label = 'training_loss')\n",
    "    plot2 = plt.plot(epoch_range, loss[1], 'g', linewidth = 1.4, label = 'validation_loss')\n",
    "#   plot3 = plt.plot(epoch_range, loss[2], 'b', linewidth = 1.4, label = 'test_loss')\n",
    "\n",
    "    plt.title('Loss Plot')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda:  True\n",
      "data loaded.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print ('use_cuda: ', use_cuda)\n",
    "\n",
    "data_dir = './input.txt'\n",
    "\n",
    "batchsize = 1\n",
    "\n",
    "dataloaders, num_chars = getDataLoader(random_seed = 0, data_dir = data_dir, seq_length = 25, \n",
    "                            batchsize = batchsize, use_cuda = use_cuda, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, hidden_size, batchsize):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.batchsize = batchsize\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, hidden_layers)\n",
    "        self.hidden = self.init_hidden()      \n",
    "        self.linear = nn.Linear(hidden_size, self.output_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(self.hidden_layers, self.batchsize, self.hidden_size)),\n",
    "                Variable(torch.zeros(self.hidden_layers, self.batchsize, self.hidden_size)))\n",
    "    \n",
    "    def forward(self, x):       \n",
    "        lstm_out, self.hidden = self.lstm(x.view(len(x), self.batchsize, -1), self.hidden)   \n",
    "#         print (lstm_out.size(), self.hidden[0].size())\n",
    "#         print ('lstm_out:\\n', lstm_out[-1])\n",
    "#         print ('hidden states:\\n', self.hidden[0])\n",
    "#         if lstm_out[-1] == self.hidden[0][0]:\n",
    "#             print ('equal')\n",
    "        lstm_out = self.linear(lstm_out)\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch: 1       loss:3.138         3.583         \n",
      "model saved.\n",
      "epoch: 2       loss:2.761         3.196         \n",
      "model saved.\n",
      "epoch: 3       loss:2.557         2.965         \n",
      "model saved.\n",
      "epoch: 4       loss:2.396         2.781         \n",
      "model saved.\n",
      "epoch: 5       loss:2.300         2.678         \n",
      "model saved.\n",
      "epoch: 6       loss:2.240         2.627         \n",
      "model saved.\n",
      "epoch: 7       loss:2.200         2.591         \n",
      "model saved.\n",
      "epoch: 8       loss:2.168         2.565         \n",
      "model saved.\n",
      "epoch: 9       loss:2.141         2.546         \n",
      "model saved.\n",
      "epoch: 10       loss:2.116         2.533         \n",
      "model saved.\n",
      "epoch: 11       loss:2.117         2.544         \n",
      "epoch: 12       loss:2.105         2.537         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-148:\n",
      "Process Process-146:\n",
      "Process Process-145:\n",
      "Process Process-147:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-17fbbb2b2cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m statlists = training(model = lstm, criterion = loss_function, optimizer = optimizer, \n\u001b[1;32m     18\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                      gamma = 0.1, use_cuda = use_cuda, model_dir = None)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# def training(model, criterion, optimizer, epochs, dataloaders, step_size = None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#              gamma = None, early_stop = False, use_cuda = False, model_dir = None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0841da7990c3>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, criterion, optimizer, epochs, dataloaders, step_size, gamma, early_stop, use_cuda, checkpoint_ind, model_dir, best_model, shuffle)\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;31m#             sys.exit(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-89c129b2d5c4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         print (lstm_out.size(), self.hidden[0].size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         print ('lstm_out:\\n', lstm_out[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             ))\n\u001b[1;32m    307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "\n",
    "lstm = LSTM(num_chars, 2, 256, batchsize)\n",
    "\n",
    "if use_cuda:\n",
    "    lstm = lstm.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n",
    "num_epoch = 20\n",
    "\n",
    "statlists = training(model = lstm, criterion = loss_function, optimizer = optimizer, \n",
    "                     epochs = num_epoch, dataloaders = dataloaders, step_size = 20, \n",
    "                     gamma = 0.1, use_cuda = use_cuda, model_dir = None)\n",
    "# def training(model, criterion, optimizer, epochs, dataloaders, step_size = None, \n",
    "#              gamma = None, early_stop = False, use_cuda = False, model_dir = None, \n",
    "#              best_model = False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "torch.Size([24, 4, 64]) torch.Size([1, 4, 64])\n",
      "lstm_out:\n",
      " Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.0142 -0.0750 -0.0304  0.0431  0.0240 -0.0460  0.0270  0.1068 -0.1055  0.0773\n",
      " 0.0456 -0.0503  0.0019  0.0250  0.0045 -0.0453  0.0056  0.1224 -0.1513  0.0828\n",
      " 0.0776 -0.0970  0.0227  0.0703 -0.0636 -0.0807 -0.0203  0.1375 -0.0802  0.0972\n",
      " 0.0497 -0.0596 -0.0446  0.0331 -0.0114 -0.0410 -0.0037  0.1251 -0.1528  0.0333\n",
      "\n",
      "Columns 10 to 19 \n",
      " 0.0922 -0.0371  0.0073  0.0150 -0.0852 -0.0875 -0.1619 -0.0351 -0.0509  0.0204\n",
      " 0.1214 -0.0429  0.0198 -0.0012 -0.1098 -0.0512 -0.1294 -0.0829 -0.1081  0.0084\n",
      " 0.0774 -0.0195  0.0766  0.0481 -0.1127 -0.0386 -0.1338 -0.0773 -0.1144 -0.0316\n",
      " 0.0508 -0.0185 -0.0077  0.0616 -0.0317 -0.0633 -0.1208 -0.0518 -0.1120 -0.0308\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.0171  0.0549  0.0336  0.0008 -0.1027  0.0456  0.0996 -0.0111  0.0471  0.0717\n",
      " 0.0130  0.0684  0.0454 -0.0047 -0.0871  0.0730  0.0948  0.0287 -0.0012  0.1026\n",
      " 0.0201  0.0013  0.0669  0.0178 -0.0770  0.0931  0.1080  0.0610  0.0359  0.0748\n",
      " 0.0161  0.0407  0.0319  0.0086 -0.0898  0.0215  0.0960  0.0383  0.0245  0.0418\n",
      "\n",
      "Columns 30 to 39 \n",
      "-0.1178 -0.0143  0.0104  0.0167  0.0684 -0.0009  0.0011  0.0084 -0.0147  0.0108\n",
      "-0.0848 -0.0487  0.0033 -0.0167  0.0340 -0.0117  0.0366  0.0008 -0.0446 -0.0355\n",
      "-0.0278 -0.0255 -0.0425 -0.0084  0.0379 -0.0180 -0.0139 -0.0014 -0.0866 -0.0251\n",
      "-0.0835 -0.0097 -0.0371  0.0033  0.0630 -0.0250  0.0267 -0.0071 -0.0380  0.0202\n",
      "\n",
      "Columns 40 to 49 \n",
      " 0.0234  0.0016  0.0586  0.0652 -0.0290  0.0539  0.0397  0.0025  0.0005 -0.0177\n",
      "-0.0344 -0.0167  0.0447  0.0786 -0.0334  0.0403  0.0023  0.0091 -0.0073  0.0099\n",
      "-0.0038 -0.0552  0.0885  0.1172 -0.0400  0.0354  0.0294  0.0386  0.0054  0.0025\n",
      "-0.0396 -0.0397  0.0736  0.1237 -0.0316  0.0579  0.0351 -0.0261  0.0015 -0.0041\n",
      "\n",
      "Columns 50 to 59 \n",
      " 0.0325 -0.0194  0.0030 -0.0173 -0.0863 -0.0215  0.0117  0.0783  0.0045  0.0817\n",
      " 0.0175 -0.0229  0.0438 -0.0468 -0.1015  0.0189  0.0461  0.0547  0.0150  0.0769\n",
      "-0.0071 -0.0070  0.0701 -0.0671 -0.0972  0.0162  0.0774  0.0014  0.0022  0.0962\n",
      " 0.0033 -0.0339  0.0019 -0.0539 -0.0799  0.0173  0.0195  0.0457 -0.0303  0.0715\n",
      "\n",
      "Columns 60 to 63 \n",
      " 0.1030  0.0228 -0.0568  0.0199\n",
      " 0.0832 -0.0171 -0.0568  0.0006\n",
      " 0.0620  0.0334 -0.0926  0.0111\n",
      " 0.0673 -0.0017 -0.0419  0.0037\n",
      "[torch.cuda.FloatTensor of size 4x64 (GPU 0)]\n",
      "\n",
      "hidden states:\n",
      " Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.0142 -0.0750 -0.0304  0.0431  0.0240 -0.0460  0.0270  0.1068 -0.1055\n",
      "  0.0456 -0.0503  0.0019  0.0250  0.0045 -0.0453  0.0056  0.1224 -0.1513\n",
      "  0.0776 -0.0970  0.0227  0.0703 -0.0636 -0.0807 -0.0203  0.1375 -0.0802\n",
      "  0.0497 -0.0596 -0.0446  0.0331 -0.0114 -0.0410 -0.0037  0.1251 -0.1528\n",
      "\n",
      "Columns 9 to 17 \n",
      "   0.0773  0.0922 -0.0371  0.0073  0.0150 -0.0852 -0.0875 -0.1619 -0.0351\n",
      "  0.0828  0.1214 -0.0429  0.0198 -0.0012 -0.1098 -0.0512 -0.1294 -0.0829\n",
      "  0.0972  0.0774 -0.0195  0.0766  0.0481 -0.1127 -0.0386 -0.1338 -0.0773\n",
      "  0.0333  0.0508 -0.0185 -0.0077  0.0616 -0.0317 -0.0633 -0.1208 -0.0518\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.0509  0.0204 -0.0171  0.0549  0.0336  0.0008 -0.1027  0.0456  0.0996\n",
      " -0.1081  0.0084  0.0130  0.0684  0.0454 -0.0047 -0.0871  0.0730  0.0948\n",
      " -0.1144 -0.0316  0.0201  0.0013  0.0669  0.0178 -0.0770  0.0931  0.1080\n",
      " -0.1120 -0.0308  0.0161  0.0407  0.0319  0.0086 -0.0898  0.0215  0.0960\n",
      "\n",
      "Columns 27 to 35 \n",
      "  -0.0111  0.0471  0.0717 -0.1178 -0.0143  0.0104  0.0167  0.0684 -0.0009\n",
      "  0.0287 -0.0012  0.1026 -0.0848 -0.0487  0.0033 -0.0167  0.0340 -0.0117\n",
      "  0.0610  0.0359  0.0748 -0.0278 -0.0255 -0.0425 -0.0084  0.0379 -0.0180\n",
      "  0.0383  0.0245  0.0418 -0.0835 -0.0097 -0.0371  0.0033  0.0630 -0.0250\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.0011  0.0084 -0.0147  0.0108  0.0234  0.0016  0.0586  0.0652 -0.0290\n",
      "  0.0366  0.0008 -0.0446 -0.0355 -0.0344 -0.0167  0.0447  0.0786 -0.0334\n",
      " -0.0139 -0.0014 -0.0866 -0.0251 -0.0038 -0.0552  0.0885  0.1172 -0.0400\n",
      "  0.0267 -0.0071 -0.0380  0.0202 -0.0396 -0.0397  0.0736  0.1237 -0.0316\n",
      "\n",
      "Columns 45 to 53 \n",
      "   0.0539  0.0397  0.0025  0.0005 -0.0177  0.0325 -0.0194  0.0030 -0.0173\n",
      "  0.0403  0.0023  0.0091 -0.0073  0.0099  0.0175 -0.0229  0.0438 -0.0468\n",
      "  0.0354  0.0294  0.0386  0.0054  0.0025 -0.0071 -0.0070  0.0701 -0.0671\n",
      "  0.0579  0.0351 -0.0261  0.0015 -0.0041  0.0033 -0.0339  0.0019 -0.0539\n",
      "\n",
      "Columns 54 to 62 \n",
      "  -0.0863 -0.0215  0.0117  0.0783  0.0045  0.0817  0.1030  0.0228 -0.0568\n",
      " -0.1015  0.0189  0.0461  0.0547  0.0150  0.0769  0.0832 -0.0171 -0.0568\n",
      " -0.0972  0.0162  0.0774  0.0014  0.0022  0.0962  0.0620  0.0334 -0.0926\n",
      " -0.0799  0.0173  0.0195  0.0457 -0.0303  0.0715  0.0673 -0.0017 -0.0419\n",
      "\n",
      "Columns 63 to 63 \n",
      "   0.0199\n",
      "  0.0006\n",
      "  0.0111\n",
      "  0.0037\n",
      "[torch.cuda.FloatTensor of size 1x4x64 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Variable objects containing non-empty torch.cuda.ByteTensor is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ea28ac7148b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                      \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                      model_dir = None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-6cc2063680fb>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, criterion, optimizer, epochs, dataloaders, step_size, gamma, early_stop, use_cuda, checkpoint_ind, model_dir, best_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-cc0c1712a765>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'lstm_out:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'hidden states:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'equal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         raise RuntimeError(\"bool value of Variable objects containing non-empty \" +\n\u001b[0;32m--> 123\u001b[0;31m                            torch.typename(self.data) + \" is ambiguous\")\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Variable objects containing non-empty torch.cuda.ByteTensor is ambiguous"
     ]
    }
   ],
   "source": [
    "# lstm = LSTM(num_chars, 1, 64, batchsize)\n",
    "\n",
    "# if use_cuda:\n",
    "#     lstm = lstm.cuda()\n",
    "#     loss_function = nn.CrossEntropyLoss().cuda()\n",
    "# else:\n",
    "#     loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "# learning_rate = 0.01\n",
    "\n",
    "# optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n",
    "# num_epoch = 100\n",
    "\n",
    "# statlists = training(model = lstm, criterion = loss_function, optimizer = optimizer, \n",
    "#                      epochs = num_epoch, dataloaders = dataloaders, step_size = 20, \n",
    "#                      gamma = 0.1, use_cuda = use_cuda, checkpoint_ind = 9, \n",
    "#                      model_dir = None)\n",
    "'''\n",
    "    outputs of lstm are just stacking of hidden states h at each time step t.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nou62ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2ae8facf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min validation loss:  1.45943165395\n"
     ]
    }
   ],
   "source": [
    "plot_loss(statlists)\n",
    "print ('min validation loss: ', np.min(statlists[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch: 1       loss:2.261         2.274         \n",
      "model saved.\n",
      "epoch: 2       loss:1.939         1.968         \n",
      "model saved.\n",
      "epoch: 3       loss:1.817         1.852         \n",
      "model saved.\n",
      "epoch: 4       loss:1.720         1.768         \n",
      "model saved.\n",
      "epoch: 5       loss:1.656         1.712         \n",
      "model saved.\n",
      "epoch: 6       loss:1.613         1.675         \n",
      "model saved.\n",
      "epoch: 7       loss:1.576         1.648         \n",
      "model saved.\n",
      "epoch: 8       loss:1.554         1.633         \n",
      "model saved.\n",
      "epoch: 9       loss:1.519         1.609         \n",
      "model saved.\n",
      "epoch: 10       loss:1.498         1.590         \n",
      "model saved.\n",
      "epoch: 11       loss:1.446         1.558         \n",
      "model saved.\n",
      "epoch: 12       loss:1.439         1.555         \n",
      "model saved.\n",
      "epoch: 13       loss:1.434         1.555         \n",
      "model saved.\n",
      "epoch: 14       loss:1.430         1.555         \n",
      "epoch: 15       loss:1.426         1.553         \n",
      "model saved.\n",
      "epoch: 16       loss:1.422         1.552         \n",
      "model saved.\n",
      "epoch: 17       loss:1.419         1.550         \n",
      "model saved.\n",
      "epoch: 18       loss:1.415         1.552         \n",
      "epoch: 19       loss:1.413         1.551         \n",
      "epoch: 20       loss:1.410         1.549         \n",
      "model saved.\n",
      "epoch: 21       loss:1.405         1.548         \n",
      "model saved.\n",
      "epoch: 22       loss:1.405         1.548         \n",
      "model saved.\n",
      "epoch: 23       loss:1.404         1.548         \n",
      "epoch: 24       loss:1.404         1.548         \n",
      "epoch: 25       loss:1.403         1.548         \n",
      "epoch: 26       loss:1.403         1.548         \n",
      "model saved.\n",
      "epoch: 27       loss:1.402         1.548         \n",
      "epoch: 28       loss:1.402         1.548         \n",
      "epoch: 29       loss:1.402         1.548         \n",
      "epoch: 30       loss:1.401         1.548         \n",
      "model saved.\n",
      "epoch: 31       loss:1.401         1.548         \n",
      "epoch: 32       loss:1.401         1.548         \n",
      "epoch: 33       loss:1.401         1.548         \n",
      "epoch: 34       loss:1.401         1.548         \n",
      "epoch: 35       loss:1.401         1.548         \n",
      "epoch: 36       loss:1.401         1.548         \n",
      "epoch: 37       loss:1.401         1.548         \n",
      "epoch: 38       loss:1.401         1.548         \n",
      "epoch: 39       loss:1.401         1.548         \n",
      "epoch: 40       loss:1.401         1.548         \n",
      "model saved.\n",
      "epoch: 41       loss:1.401         1.548         \n",
      "epoch: 42       loss:1.401         1.548         \n",
      "epoch: 43       loss:1.401         1.548         \n",
      "epoch: 44       loss:1.401         1.548         \n",
      "epoch: 45       loss:1.401         1.548         \n",
      "epoch: 46       loss:1.401         1.548         \n",
      "epoch: 47       loss:1.401         1.548         \n",
      "epoch: 48       loss:1.401         1.548         \n",
      "epoch: 49       loss:1.401         1.548         \n",
      "epoch: 50       loss:1.401         1.548         \n",
      "model saved.\n",
      "training finished.\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(num_chars, 1, 128, num_chars)\n",
    "\n",
    "if use_cuda:\n",
    "    lstm = lstm.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n",
    "num_epoch = 50\n",
    "\n",
    "statlists = training(model = lstm, criterion = loss_function, optimizer = optimizer, \n",
    "                     epochs = num_epoch, dataloaders = dataloaders, step_size = 10, \n",
    "                     gamma = 0.1, use_cuda = use_cuda, checkpoint_ind = 2, \n",
    "                     model_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4FfXZ//H3nYUsENYsrApubCqg\niIDiXguKKyK1VgUXKo9VrNpq+1hbrdpFf9pSFR/cWi1VEYVqW0BFLKUiCqiogCsgm1nYCQSy3L8/\n5iQESEhIcjJJzud1XXOdOTNzZu6ReD5ntu/X3B0RERGAuLALEBGRhkOhICIiZRQKIiJSRqEgIiJl\nFAoiIlJGoSAiImUUCiIhMbPTzGxN2HWIlKdQkJhgZivN7KwQtjvazIrNbLuZbTWzD81seA3W82cz\nuzcaNYqUp1AQib757t4CaA08BUwxszYh1yRSIYWCxDwzu87MvjSzjWb2qpl1jEw3M3vYzHIiv/I/\nNrOjI/POMbOlZrbNzNaa2W1VbcfdS4CngRTg8Arq6Glmb5vZZjP71MzOj0wfC1wO/DRyxPFaHe6+\nyF4UChLTzOwM4DfApUAHYBXwQmT22cApwFFAq8gyGyLzngJ+6O5pwNHAW9XYVgJwLbAd+GKfeYnA\na8DrQCZwIzDZzLq7+yRgMvB7d2/h7ufVeIdFqqBQkFh3OfC0uy92913Az4BBZtYVKATSgB6Aufsy\nd18f+Vwh0MvMWrr7JndffIBtDDSzzcC3wGXARe6+Zd9lgBbAb919t7u/BfwjsrxIvVEoSKzrSHB0\nAIC7byc4GugU+WJ+BHgUyDGzSWbWMrLoCOAcYJWZ/dvMBh1gG++6e2t3T3f3ge7+ZiV1rI6cYiq1\nCuhU810TOXgKBYl164BDS9+YWXOgHbAWwN0nuPvxQC+C00g/iUx/390vIDjVMx2YUgd1dDGz8v9P\nHlJaB6DmjKVeKBQkliSaWXK5IQF4HhhjZn3NLAm4H1jg7ivN7AQzOzFyvj8fKABKzKyZmV1uZq3c\nvRDYCpRUutXqWQDsILiYnGhmpwHnsef6RjZwWC23IVIlhYLEkn8BO8sNv4qcyvkF8DKwnuCuoO9F\nlm8JPAFsIjiVswF4IDLvCmClmW0Frie4NlFj7r6bIASGAXnAY8CV7r48sshTBNcwNpvZ9NpsS+RA\nTJ3siIhIKR0piIhIGYWCiIiUUSiIiEgZhYKIiJRJCLuAg5Wenu5du3YNuwwRkUZl0aJFee6eUdVy\njS4UunbtysKFC8MuQ0SkUTGzVVUvpdNHIiJSjkJBRETKKBRERKRMo7umICL1p7CwkDVr1lBQUBB2\nKVJNycnJdO7cmcTExBp9XqEgIpVas2YNaWlpdO3aFTMLuxypgruzYcMG1qxZQ7du3Wq0Dp0+EpFK\nFRQU0K5dOwVCI2FmtGvXrlZHdgoFETkgBULjUtt/r5gJha83fc1v5/2W/N35YZciItJgxVQo/Gz2\nz1i3bV3YpYiINFgxEwpZzbMAyM7PDrkSEamuzZs389hjjx3058455xw2b958wGXuuusu3nyzou6y\na65FixZ1ur4wxE4o5O4AIHtDtZ70FpEGoLJQKCoqOuDn/vWvf9G6desDLnPPPfdw1lln1aq+pihm\nbkltt34zcSWQvf5L6Bd2NSKNUH4+LF9e9XIHq0cPaN68wll33HEHX331FX379iUxMZHk5GTatGnD\n8uXL+fzzz7nwwgtZvXo1BQUFjB8/nrFjxwJ72kjbvn07w4YN4+STT+add96hU6dO/P3vfyclJYXR\no0czfPhwLrnkErp27cpVV13Fa6+9RmFhIS+99BI9evQgNzeX73//+6xbt45BgwbxxhtvsGjRItLT\n0w+4S+7OT3/6U2bMmIGZceeddzJq1CjWr1/PqFGj2Lp1K0VFRUycOJHBgwdzzTXXsHDhQsyMq6++\nmh//+Md1/p+52ty9UQ3HH3+818hHH3nWbfhdz46p2edFYtDSpUv3vFm40B3qfli4sNLtr1ixwnv3\n7u3u7nPmzPHU1FT/+uuvy+Zv2LDB3d137NjhvXv39ry8PHd3P/TQQz03N9dXrFjh8fHx/sEHH7i7\n+8iRI/25555zd/errrrKX3rppbLlJ0yY4O7ujz76qF9zzTXu7n7DDTf4/fff7+7uM2bMcMBzc3Mr\nrbd58+bu7j516lQ/66yzvKioyL/99lvv0qWLr1u3zh988EG/99573d29qKjIt27d6gsXLvSzzjqr\nbB2bNm064L9Jdez17xYBLPRqfMfGzJECmZlkbYfsLWvDrkSkcerRA6LRQnGPHtVedMCAAXs9lDVh\nwgSmTZsGwOrVq/niiy9o167dXp/p1q0bffv2BeD4449n5cqVFa774osvLlvmlVdeAWDevHll6x86\ndCht2rSpVp3z5s3jsssuIz4+nqysLE499VTef/99TjjhBK6++moKCwu58MIL6du3L4cddhhff/01\nN954I+eeey5nn312tf97REPshEJ6Oln5kL09J+xKRBqn5s3h+ONDLmHPaaa3336bN998k/nz55Oa\nmsppp51W4UNbSUlJZePx8fHs3LmzwnWXLhcfH1/lNYuaOuWUU5g7dy7//Oc/GT16NLfccgtXXnkl\nH330EbNmzeLxxx9nypQpPP3001HZfnXEzIVmEhLIKmxGzq6NYVciItWUlpbGtm3bKpy3ZcsW2rRp\nQ2pqKsuXL+fdd9+t8+2fdNJJTJkyBYDXX3+dTZs2VetzQ4YM4cUXX6S4uJjc3Fzmzp3LgAEDWLVq\nFVlZWVx33XVce+21LF68mLy8PEpKShgxYgT33nsvixcvrvP9OBixc6QAZNGC+cVbwi5DRKqpXbt2\nnHTSSRx99NGkpKSQlZVVNm/o0KE8/vjj9OzZk+7duzNw4MA63/4vf/lLLrvsMp577jkGDRpE+/bt\nSUtLq/JzF110EfPnz6dPnz6YGb///e9p3749f/nLX3jggQdITEykRYsWPPvss6xdu5YxY8ZQUlIC\nwG9+85s634+DYcH1h8ajf//+XtOe1x644jDu6baabfcU1nFVIk3TsmXL6NmzZ9hlhGbXrl3Ex8eT\nkJDA/PnzGTduHB9++GHYZVWpon83M1vk7v2r+mxMHSlkJrdje/wKdhTuIDUxNexyRKSB++abb7j0\n0kspKSmhWbNmPPHEE2GXFHUxFQpZLdoDkL09m25tatasrIjEjiOPPJIPPvhgr2kbNmzgzDPP3G/Z\n2bNn73fnU2MUW6HQuhMQNHWhUBCRmmjXrl2jOIVUU7Fz9xGQ1fYQALK3rQ+5EhGRhilqoWBmXcxs\njpktNbNPzWx8BctcbmZLzOxjM3vHzPpEqx6AjPaHAZCdsyKamxERabSieaRQBNzq7r2AgcANZtZr\nn2VWAKe6+zHAr4FJUayHxKyOtNsB2bkKBRGRikTtmoK7rwfWR8a3mdkyoBOwtNwy75T7yLtA52jV\nA+xp6mLTmqhuRkSksaqXawpm1pWgbdIFB1jsGmBGJZ8fa2YLzWxhbm5uzQvJzCQrH3K2f1vzdYhI\ng1bap8G6deu45JJLKlzmtNNOo6rnnf7whz+wY8eOsvfV6aPhYIwePZqpU6fW2frqStRDwcxaAC8D\nN7v71kqWOZ0gFG6vaL67T3L3/u7ePyMjo+bFtG5NVr6RvSOv5usQkUahY8eOtfrS3TcUqtNHQ1MQ\n1VtSzSyRIBAmu/srlSxzLPAkMMzdN0SzHuLiyPQUPiisXvslIrJH/u58lufVfX8KPdJ70LxZxf0p\nQNCnQpcuXbjhhhsA+NWvfkVCQgJz5sxh06ZNFBYWcu+993LBBRfs9bmVK1cyfPhwPvnkE3bu3MmY\nMWP46KOP6NGjx16N4o0bN47333+fnTt3cskll3D33XczYcIE1q1bx+mnn056ejpz5swp66MhPT2d\nhx56qKzRumuvvZabb76ZlStXVtp3Q1Vmz57NbbfdRlFRESeccAITJ04kKSmJO+64g1dffZWEhATO\nPvtsHnzwQV566SXuvvtu4uPjadWqFXPnzq3Jf/ZKRS0UzMyAp4Bl7v5QJcscArwCXOHun0erlvKy\n4lqS7WoUT+RgLc9bTv8nqmwl4aAtvG4hx3esvPXVUaNGcfPNN5eFwpQpU5g1axY33XQTLVu2JC8v\nj4EDB3L++ecTfO3sb+LEiaSmprJs2TKWLFnCcccdVzbvvvvuo23bthQXF3PmmWeyZMkSbrrpJh56\n6CHmzJmzX4c6ixYt4plnnmHBggW4OyeeeCKnnnoqbdq04YsvvuD555/niSee4NJLL+Xll1/mBz/4\nwQH3v6CggNGjRzN79myOOuoorrzySiZOnMgVV1zBtGnTWL58OWZWdurqnnvuYdasWXTq1KlOT2eV\niuaRwknAFcDHZlb6pMfPgUMA3P1x4C6gHfBY5B+zqDptc9RGVrM2bI77ll1Fu0hKSKr6AyICBL/o\nF15X9/0p9Eg/cH8K/fr1Iycnh3Xr1pGbm0ubNm1o3749P/7xj5k7dy5xcXGsXbuW7Oxs2rdvX+E6\n5s6dy0033QTAsccey7HHHls2b8qUKUyaNImioiLWr1/P0qVL95q/r3nz5nHRRReVNeN98cUX85//\n/Ifzzz+/2n03lPfZZ5/RrVs3jjrqKACuuuoqHn30UX70ox+RnJzMNddcw/Dhwxk+fDgQtNw6evRo\nLr300rI+IOpSNO8+mgdUHNt7lrkWuDZaNVQkKzUTWEZOfg5dWnWpz02LNGrNmzU/4C/6aBo5ciRT\np07l22+/ZdSoUUyePJnc3FwWLVpEYmIiXbt2rbAvhaqsWLGCBx98kPfff582bdowevToGq2nVHX7\nbqiOhIQE3nvvPWbPns3UqVN55JFHeOutt3j88cdZsGAB//znPzn++ONZtGhRnTavEVNPNANktewA\nBE1diEjjMGrUKF544QWmTp3KyJEj2bJlC5mZmSQmJjJnzhxWrVp1wM+fcsop/O1vfwPgk08+YcmS\nJQBs3bqV5s2b06pVK7Kzs5kxY88NkJX15TBkyBCmT5/Ojh07yM/PZ9q0aQwZMqTG+9a9e3dWrlzJ\nl19+CcBzzz3Hqaeeyvbt29myZQvnnHMODz/8MB999BEAX331FSeeeCL33HMPGRkZrF69usbbrkhM\ntX0EkNWmCxQFjeKJSOPQu3dvtm3bRqdOnejQoQOXX3455513Hscccwz9+/enRxVdeo4bN44xY8bQ\ns2dPevbsyfGRHuT69OlDv3796NGjB126dOGkk04q+8zYsWMZOnQoHTt2ZM6cOWXTjzvuOEaPHs2A\nAQOA4EJzv379qnWqqCLJyck888wzjBw5suxC8/XXX8/GjRu54IILKCgowN156KHg0uxPfvITvvji\nC9ydM888kz596rYhiJjqTwGg4ImJpKz7H5465/+4+oSxdViZSNMT6/0pNFa16U8h5k4fJWd1olWB\nmroQEalIzJ0+Km3qImdD3Z6HExGpyA033MB///vfvaaNHz+eMWPGhFTRgcVmKORD9tZ1YVci0ii4\ne6X3/0vVHn300XrdXm0vCcTc6SMyMsjM191HItWRnJzMhg0bav1FI/XD3dmwYQPJyck1XkfsHSm0\naEHWzniW79JTzSJV6dy5M2vWrKFWDVFKvUpOTqZz55o3OB17oWBGlrUgu3hL2JWINHiJiYl066au\na2NJ7J0+ArISWrOBnRSVFIVdiohIgxKboZDcDjfIzdchsYhIebEZCi2yAF1sFhHZV2yGQuvgIoya\nuhAR2VtshkJ6VwBy8nPCLUREpIGJyVBontWZ5rshe5OeahYRKS8mQ4HMzOABtrwDN7crIhJrYjMU\nMjLI2g7Zm3WkICJSXmyGQmn7R9u+DbsSEZEGJTZDofRIYWde2JWIiDQosRkKyclkFTUju3Bz2JWI\niDQosRkKQFZcS3J9OyVeEnYpIiINRuyGQrO2FJuzYceGsEsREWkwYjcUUjMBNXUhIlJe7IZCqw6A\nnmoWESkvdkOh7SGA2j8SESkvZkOhZUYXmhVB9nY9qyAiUipmQ8GysoIH2DbqqWYRkVIxGwplD7Bt\n/CbsSkREGozYDYXSpi62rAu7EhGRBiO2Q2E7ZO/Q3UciIqViNxTatQuOFHZtDLsSEZEGI3ZDISGB\nLG9OTslW3D3sakREGoTYDQUgK6EVuylmc4EaxhMRgVgPhZR0QE81i4iUiulQyExrD6j9IxGRUjEd\nClmtOwNq6kJEpFTUQsHMupjZHDNbamafmtn4CpYxM5tgZl+a2RIzOy5a9VSkbXoX4kt0pCAiUiqa\nRwpFwK3u3gsYCNxgZr32WWYYcGRkGAtMjGI9+4nLzCIzH7K3ra/PzYqINFhRCwV3X+/uiyPj24Bl\nQKd9FrsAeNYD7wKtzaxDtGraT+kDbGr/SEQEqKdrCmbWFegHLNhnVieg/DfyGvYPDsxsrJktNLOF\nubm5dVdYaVMXm9bU3TpFRBqxqIeCmbUAXgZudvetNVmHu09y9/7u3j8jI6Puiis9UlDz2SIiQJRD\nwcwSCQJhsru/UsEia4Eu5d53jkyrH6VHCgV59bZJEZGGLJp3HxnwFLDM3R+qZLFXgSsjdyENBLa4\ne/1d9W3dmqwdceQUbqm3TYqINGQJUVz3ScAVwMdm9mFk2s+BQwDc/XHgX8A5wJfADmBMFOvZnxlZ\n8WnsYAvbd2+nRbMW9bp5EZGGJmqh4O7zAKtiGQduiFYN1ZGZ1A7YQvb2bFq0VSiISGyL6SeaAbJS\nMwE9wCYiAgoF2rfqCMDarfV3fVtEpKGK+VDIbHcI7XfG897a98IuRUQkdDEfCpaRySmr4/jPN/8J\nuxQRkdDFfCiQmcmQLwtZtH4R+bvzw65GRCRUCoXMTIasgqKSIhas3bcVDhGR2KJQyMzk6BxoldCC\n/6zSKSQRiW0KhcxM4h1OatFL1xVEJOYpFDp0gIQEhuzKYv6a+RQWF4ZdkYhIaBQKycnQrx9DPtvJ\njsIdLF6/OOyKRERCo1AAGDSI/nM+Jyk+SaeQRCSmKRQABg8macU3nJjRT6EgIjFNoQAweDAAQ4o7\nMe+beZR4ScgFiYiEQ6EA0KULdO7MkJXOxp0bWZa7LOyKRERCoVAoNWgQg99ZTZypyQsRiV0KhVKD\nB5P2/kf0y+qrUBCRmKVQKDV4MOzezZBmR+jJZhGJWQqFUn37QnIyQ7KTWb11Nas2rwq7IhGReqdQ\nKNWsGZxwAicvzgPQKSQRiUkKhfIGDSLzP4vp3q67TiGJSExSKJQ3eDB8+y1D2uhis4jEJoVCeYMG\nATBka2uW5S0jb0deyAWJiNQvhUJ5mZlwxBEMWRr0wDbvm3khFyQiUr8UCvsaPJiu//2ETmmdmLtq\nbtjViIjUK4XCvgYNwj5awpCOg3RdQURiTrVCwczGm1lLCzxlZovN7OxoFxeKwYOhpIRTijrxwfoP\n2L57e9gViYjUm+oeKVzt7luBs4E2wBXAb6NWVZh694a0NIasKKbYi5m/en7YFYmI1JvqhoJFXs8B\nnnP3T8tNa1ri42HgQHq9+xVtU9ry9sq3w65IRKTeVDcUFpnZ6wShMMvM0oCm2+nAoEHEzX+XoYd/\nl79/9vewqxERqTfVDYVrgDuAE9x9B5AIjIlaVWEbPBg2bWJEy4F8mvspn+V9FnZFIiL1orqhMAj4\nzN03m9kPgDuBLdErK2QnnghmDF2ZQGpiKi8veznsikRE6kV1Q2EisMPM+gC3Al8Bz0atqrC1bg29\ne5O6YDHDjhimUBCRmFHdUChydwcuAB5x90eBtOiV1QAMHgzvvMOIniNYvH4xKzatCLsiEZGoq24o\nbDOznxHcivpPM4sjuK7QdA0aBMuWcW7GIJrFN+OVZa+EXZGISNRVNxRGAbsInlf4FugMPBC1qhqC\nwYMBaLl4KWcffrZOIYlITKhWKESCYDLQysyGAwXu3nSvKQAceSSkp8N//8uIniOYv2Y+a7euDbsq\nEZGoqm4zF5cC7wEjgUuBBWZ2SRWfedrMcszsk0rmtzKz18zsIzP71Mwa1i2uZnDGGTBrFud3P5+E\nuASmLZ8WdlUiIlFV3dNH/0vwjMJV7n4lMAD4RRWf+TMw9ADzbwCWunsf4DTg/5lZs2rWUz+GDoVF\ni2i7rYjTu56uU0gi0uRVNxTi3D2n3PsNVX3W3ecCGw+0CJBmZga0iCxbVM166sfQSKbNmsWIniOY\nu2ouufm54dYkIhJF1Q2FmWY2y8xGm9lo4J/Av2q57UeAnsA64GNgvLs3rKYzOnSAPn1g5kwu6HEB\n7s705dPDrkpEJGqqe6H5J8Ak4NjIMMndb6/ltr8LfAh0BPoCj5hZy4oWNLOxZrbQzBbm5tbzL/Vh\nw2DWLNqnZHDyISfrFJKINGnV7mTH3V9291siQ11ccR0DvOKBL4EVQI9Ktj3J3fu7e/+MjIw62PRB\nGDoUNmyARYsY0XMEs1fMZtPOTfVbg4hIPTlgKJjZNjPbWsGwzcy21nLb3wBnRraTBXQHvq7lOuve\n4MGQlgYzZnBxz4spKinitc9fC7sqEZGoqOpicZq7t6xgSHP3Ck/1lDKz54H5QHczW2Nm15jZ9WZ2\nfWSRXwODzexjYDZwu7vn1cVO1anERDjrLJg5ky6tujCg0wCdQhKRJishWit298uqmL+OoCe3hm/Y\nMPjhD2HDBkb0HMFdc+5i265tpCU17eafRCT2VPuaQkwbOhTc4Y03GNFzBLuKd/GvL2p785WISMOj\nUKiOLl2CvptnzODwtofTJ6sPL376YthViYjUOYVCdQ0dCrNmQUkJ1/S7hr9/9nf1yCYiTY5CobqG\nDYPsbPjwQ6497loym2dy/7z7w65KRKROKRSq6+SToXlzmDmTlMQUbj/pdiYvmcyXG78MuzIRkTqj\nUKiupKSg1dQZMwAYe/xY2qW24zf/+U3IhYmI1B2FwsEYNgzmz4fNm0lNTOUng3/Cs0ueVVedItJk\nKBQOxtChUFwMb74JwPX9r6d1cmt+O++3IRcmIlI3FAoHo1s36N697BRSi2YtuHXQrTzz4TN8s+Wb\nkIsTEak9hcLBGjoUZs4MHmYDbjjhBtKS0vjdvN+FXJiISO0pFA7WsGGwbh18/DEAaUlp/Hjgj3ny\ngyfVh7OINHoKhYN1yimQnBwcLUTcOOBGUhJS+N1/dbQgIo2bQuFgpaTA6afD9D09sLVKbsXNA29m\n0qJJrN+2PsTiRERqR6FQE6NHB7emfvhh2aTxJ44nKSGJB955ILy6RERqSaFQExddBJ06wZ/+VDap\nTUobbhpwE4+9/xgfZ38cYnEiIjWnUKiJxES4/nqYPBny9vQL9LMhP+Pwtoczauoo8nfnh1igiEjN\nKBRqauzY4LbUJ58sm5SamMqLl7zIis0ruHnmzSEWJyJSMwqFmsrMhO99Dx57DIqKyiYfnXk0fxz6\nR5784Ele+OSFEAsUETl4CoXauPFGWL0aXn11r8nXHXcdI3uNZOxrY/l609chFScicvAUCrXRvz8M\nHAgTJuw12cyYdN4k2qW247KXL2N38e6QChQROTgKhdq66Sb4979hyZK9JrdObs3zI55n8frF3PnW\nnSEVJyJycBQKtTViBLRvD488st+sgZ0Hct8Z9/HAOw8w88uZFXxYRKRhUSjUVrNmwe2pf/0rbNy4\n3+zbBt/G2YefzZXTruSrjV+FUKCISPUpFOrCD38Y3IH01FP7zYqzOJ698FlaJbdiyDNDWJq7NIQC\nRUSqR6FQF9q3h0svDW5PLS7eb3ZWiyzmjp5Lm5Q2nPrnU/nw2w8rWImISPgUCnXlxhth5Ur4xz8q\nnN0hrQP/Hv1vurTswul/OZ0FaxbUb30iItWgUKgrJ54IJ5yw3+2p5aWnpvPWVW/RI70HZz13FnNX\nza3HAkVEqqZQqEu33gpvvVXp0QIEt6q+/oPX6d+xP0P/OpTXv3q9HgsUETkwhUJduvRSOPNM+J//\nge3bK10sLSmNf33/X5za9VTOe/48Hp7/MIXFhfVYqIhIxRQKdckMHn8ccnPhF7844KIpiSlMHzWd\nq/teza2v38oxE49hxhcz6qlQEZGKKRTq2hFHwF13BdcWFi484KJJCUlMHD6RRWMXkdUii3P+dg7n\nTD6H5XnL66lYEZG9KRSi4bbboFcvuO66vVpQrUy/Dv14+6q3mXLJFJbmLuWYicdw88yb2VywuR6K\nFRHZQ6EQDYmJ8MQT8NFH8Mc/VusjZsbI3iNZdsMyfnnqL3li8RMMeGKAnoIWkXqlUIiWgQODC853\n3RU8v1BNKYkp3HnKnXz4ww9xnEFPDdIzDSJSbxQK0XT//dCmDYwbF/TSdhCObHck71z9Doe3PZzT\n/3I605dPj1KRIiJ7KBSiqWVL+NOfYOZMePHFg/54RvMM3rryLYYdOYyLX7yYCQsqfzBORKQuKBSi\n7aKL4MILYfx4yMs76I+nJKYw5ZIp3DzwZsbPHM8ts26hxEuiUKiISBRDwcyeNrMcM/vkAMucZmYf\nmtmnZvbvaNUSukceCe5CuvJKKDn4L/T4uHge+u5D/OG7f+AP7/6BC1+4kNz83CgUKiKxLppHCn8G\nhlY208xaA48B57t7b2BkFGsJV6dO8OyzMGMG/O53NV7N+IHjmf696fx39X/p/VhvXWcQkToXtVBw\n97nA/r3O7PF94BV3/yayfE60amkQzj0X7rgD7rwz6L6zhs7vfj6fjPuEAZ0GcNGLF3HV9Kv0PIOI\n1JkwrykcBbQxs7fNbJGZXVnZgmY21swWmtnC3NxGfNrk17+Gk06C730PsrNrvJoOaR147bLXeOr8\np5i2bBrHTDyGN756ow4LFZFYFWYoJADHA+cC3wV+YWZHVbSgu09y9/7u3j8jI6M+a6xbCQnwwgtB\nRzyXX15hhzzVZWZc3e9qloxbwhFtj+Dsv57NTTNuorik5usUEQkzFNYAs9w9393zgLlAnxDrqR8d\nO8LkyUET27/+da1X17V1V2ZfOZuHv/swj7z3CHe8eUcdFCkisSrMUPg7cLKZJZhZKnAisCzEeurP\nd74TPOl8zz3wRu1P+8RZHDcPvJkHvvMAD85/kCcXP1kHRYpILEqI1orN7HngNCDdzNYAvwQSAdz9\ncXdfZmYzgSVACfCku1d6+2rANpJZAAAOoElEQVST84tfwLx5wWmk99+HQw+t9SpvGXQLn234jHH/\nHEe31t0487Az66BQEYkl5gfZ/ELY+vfv7wuraJK60cjOhgEDoKAAXn4ZTj651qssLC5k2ORhLFy3\nkHevfZce6T3qoFARaezMbJG7969qOT3RHKasLHjvPTjySDjjDPi//6v1KhPjE5l66VQ6pHXg3L+d\nS96Og3+KWkRil0IhbFlZwUXnq6+G668Pht27a7XK1smt+cdl/2BLwRYuevEidhXtqqNiRaSpUyg0\nBM2aBd14Pv44PPVU0M9zLZ5jADi87eFM/9503lv7Hle/ejXLcpexcedGGtvpQhGpX7qm0NDMmwcj\nRgRB8dpr0LdvrVY3eclkfjDtB2XvE+MSyWyeSVaLLLKaZ5GSmEK8xRMfF0+cxe0Zr+T3QrP4ZqSn\nppcNGc0zSE9Np21KW5rFN6NZfDMS4xKD1/hE4i0eM6t2ve6O48SZfq+I1KXqXlNQKDREq1fDeedB\nTg4sXgzt29dqdSs3r2TFphXk5OeQnZ9N9vZssvOzycnPoaCogGIvprikeK/XyhQUFZC3I4+8HXns\nLq76NFecxdEmuU1ZeKSnppORmkG7lHYUFBWQuyOXnPycPa/5uRSWFJIUn0RKYgrJCcmkJKSQkphC\ni2YtyEjNILN5JpnNM8vG01PTSU5IJikhKXiNTyIpIYmk+KQ9QRWfWBZYBwopd6fYi9ldvJtdRbvY\nXbyb3cW7KfZiEuISSIhLIDEuMXiND17jLQjUgwm/ipR4Sdn2yg9FJUVlgR1nccTHxe+1TcP2e61w\n39j7//UD/b9ffl8qW1/pOkvXs+/4vtvYd/uVbvsA24t1qYmpNG/WvEafVSg0duvWwXHHBRehZ88O\njhwaEHdn2+5tZQGxcedGdhfvprC4MHgtKaSwuJCCogI2FWwiNz+XvJ15wWvkM8kJycGXe/MMMlMj\nr80zSYpPoqCogJ1FO9lZuLNsfNvubeTmB+FROuws2nnQtSfEJRBncft9gQEUlxRX+8trX4btdcRV\n+iXpOCVeUjZeky9KEYB7T7+X/z3lf2v02eqGQtSeU5Ba6tgRXnopuCvp1luDznoaEDOjZVJLWia1\n5LA2h4VWR/7ufPJ25FFQVMCu4l3sKtq113hpQJUPrN3Fu8u+jEt/XZeOx1kcSQl7jjBKjzbiLI6i\nkiKKSorKAq90vMRLKC4ppsRLgvHIEVfpr/Z9f9FXdmoszuIqPLpJiEvYs+7IkVzpePngKf9a2S/9\nfY9m9v1Vvu8v/MpCq3QbpZ+v7Eilqu3tt95y2zvQfsSqXhm9or4NhUJDNmQIPPQQ3HQTnHBC0B+D\n7KV5s+Y1PpwWkf3pal5D96MfwRVXwA9/GFxfEBGJIoVCQ2cWPNTWowdcfHGNuvQUEakuhUJjkJIC\n06bBtm1w2WW1anJbRORAFAqNRdeuQV8Mb70Ft9xSo76eRUSqolBoTL7zneDC84QJcNFFsGVL2BWJ\nSBOjUGhsxo+H6dNhzpyghdWlS8OuSESaEIVCY3TBBUEfDPHxQTBMnRp2RSLSRCgUGqvu3WHBAhg6\nFEaOhDvu0AVoEak1hUJjlpYWPPX829/CAw/A8OEKBhGpFYVCY2cGt98eXGeYORP++tewKxKRRkyh\n0FScdx5ceCHcdRfsUqc6IlIzCoWm5N57Yc2aoLMeEZEaUCg0Jb17B+0k3Xdf8PSziMhBUig0Nb/6\nVfBQ28MPh12JiDRCCoWmpmtXGDcOHnwQcnPDrkZEGhmFQlP0858HbSP95jdhVyIijYxCoSnKzAx6\na3vsMfjmm7CrEZFGRKHQVN16K7RoAXffHXYlItKIKBSaqpYt4X//F/78Z1i2LOxqRKSRUCg0ZePG\nQadO8ItfhF2JiDQSCoWmLDk5uEX15ZfhjDPg/vvhvffUPpKIVEqh0NRddRU8+mgQEPfdByeeCOnp\nQX/Pjz0GCxdCfn7YVYpIA2HuHnYNB6V///6+cOHCsMtonHbvhnffhTffDIbSowYz6NYNjj56z9Cj\nBxx+eHBtQkQaPTNb5O79q1xOoRDDtm2DTz+FTz7Ze8jO3rNMenoQDkccEbweeST06hWERmpqeLWL\nyEGpbigk1Ecx0kClpcHAgcFQXl4efP45fPVVMHz5ZfD6+ut7npIuPbro3TsIiV69gtA4/HDIygrm\ni0ijo1CQ/aWnB8PgwfvP27Qp6Bd66dLgKGPpUnjuOVi3bs8yKSlw2GFBQBx2WND0xqGH7nlt3Vqh\nIdJAKRTk4LRpAyedFAzlbd0KK1YERxRff71n+Mc/gqeqd+/es2zLlntCYt+hWzeFhkiIFApSN1q2\nhD59gmFfJSXw7bewalUwrFwZDKtWwRtvBOMFBXuWT0mB9u2D01Dlh/btoUuXPUPbtgoPkToWtVAw\ns6eB4UCOux99gOVOAOYD33P3qdGqR0IUFwcdOwbDoEH7zy8pgZycIBxWrIC1a4OL3Tk5wet77+15\nX/4Zi9RU6Nw5OOo48kg46ijo3j14PfRQiI+vt10UaSqieaTwZ+AR4NnKFjCzeOB3wOtRrEMauri4\n4Cigffv9L3qXV1QUHHGsXr33sHIlvP02PPnkntNUzZoF1zRat4akpOA5jdIhKSmYn5AAiYnBa/nx\n+PhgKB0vfS2dn5i493jp50uX3fdzFa2zsmHf+XFxOhqSehW1UHD3uWbWtYrFbgReBk6IVh3ShCQk\nBEcGnTtXfMRRVBSckvr8c/jss+Cuqe3bg1NTBQWwcyds3hy8FhYGyxcV7T9eXBwMRUV7XkvHw1BR\naJS+mu0ZSgOkdIDKx0uVf19+uYpeazteneVqsu36Fua2r78exoyJ6iZCu6ZgZp2Ai4DTqSIUzGws\nMBbgkEMOiX5x0jglJOy5LXbYsLpfv/v+QVIaIqXTS8OjqnApLg5Om5WOlx/KL7Pv+33H3YOhpGTv\n8dJ6K3qt7rzqjFd3PbXZRlXrrY2G+JzWgWrKyIj65sO80PwH4HZ3L7EqktfdJwGTIHh4rR5qE9mf\n2Z5TRykpYVcjEhVhhkJ/4IVIIKQD55hZkbtPD7EmEZGYFloouHu30nEz+zPwDwWCiEi4onlL6vPA\naUC6ma0BfgkkArj749HaroiI1Fw07z667CCWHR2tOkREpPrUn4KIiJRRKIiISBmFgoiIlFEoiIhI\nmUbX85qZ5QKrqlgsHcirh3IaGu137InVfdd+H7xD3b3KR6IbXShUh5ktrE63c02N9jv2xOq+a7+j\nR6ePRESkjEJBRETKNNVQmBR2ASHRfseeWN137XeUNMlrCiIiUjNN9UhBRERqQKEgIiJlmlwomNlQ\nM/vMzL40szvCridazOxpM8sxs0/KTWtrZm+Y2ReR1zZh1hgNZtbFzOaY2VIz+9TMxkemN+l9N7Nk\nM3vPzD6K7PfdkendzGxB5O/9RTNrFnat0WBm8Wb2gZn9I/K+ye+3ma00s4/N7EMzWxiZFvW/8yYV\nCmYWDzwKDAN6AZeZWa9wq4qaPwND95l2BzDb3Y8EZkfeNzVFwK3u3gsYCNwQ+Tdu6vu+CzjD3fsA\nfYGhZjYQ+B3wsLsfAWwCrgmxxmgaDywr9z5W9vt0d+9b7tmEqP+dN6lQAAYAX7r71+6+G3gBuCDk\nmqLC3ecCG/eZfAHwl8j4X4AL67WoeuDu6919cWR8G8EXRSea+L57YHvkbWJkcOAMYGpkepPbbwAz\n6wycCzwZeW/EwH5XIup/500tFDoBq8u9XxOZFiuy3H19ZPxbICvMYqLNzLoC/YAFxMC+R06hfAjk\nAG8AXwGb3b0oskhT/Xv/A/BToCTyvh2xsd8OvG5mi8xsbGRa1P/Ow+yjWaLI3d3Mmuz9xmbWAngZ\nuNndt0b6+gaa7r67ezHQ18xaA9OAHiGXFHVmNhzIcfdFZnZa2PXUs5Pdfa2ZZQJvmNny8jOj9Xfe\n1I4U1gJdyr3vHJkWK7LNrANA5DUn5HqiwswSCQJhsru/EpkcE/sO4O6bgTnAIKC1mZX+uGuKf+8n\nAeeb2UqC08FnAH+k6e837r428ppD8CNgAPXwd97UQuF94MjInQnNgO8Br4ZcU316FbgqMn4V8PcQ\na4mKyPnkp4Bl7v5QuVlNet/NLCNyhICZpQDfIbieMge4JLJYk9tvd/+Zu3d2964E/z+/5e6X08T3\n28yam1la6ThwNvAJ9fB33uSeaDazcwjOQcYDT7v7fSGXFBVm9jxwGkFTutnAL4HpwBTgEILmxS91\n930vRjdqZnYy8B/gY/acY/45wXWFJrvvZnYswYXFeIIfc1Pc/R4zO4zgF3Rb4APgB+6+K7xKoydy\n+ug2dx/e1Pc7sn/TIm8TgL+5+31m1o4o/503uVAQEZGaa2qnj0REpBYUCiIiUkahICIiZRQKIiJS\nRqEgIiJlFAoiEWZWHGmRsnSos8bGzKxr+RZtRRoqNXMhssdOd+8bdhEiYdKRgkgVIu3a/z7Stv17\nZnZEZHpXM3vLzJaY2WwzOyQyPcvMpkX6PvjIzAZHVhVvZk9E+kN4PfJkMmZ2U6R/iCVm9kJIuykC\nKBREykvZ5/TRqHLztrj7McAjBE/MA/wJ+Iu7HwtMBiZEpk8A/h3p++A44NPI9COBR929N7AZGBGZ\nfgfQL7Ke66O1cyLVoSeaRSLMbLu7t6hg+kqCDm6+jjTG9627tzOzPKCDuxdGpq9393QzywU6l292\nIdLM9xuRzlEws9uBRHe/18xmAtsJmimZXq7fBJF6pyMFkerxSsYPRvm2eYrZc03vXIIeA48D3i/X\n+qdIvVMoiFTPqHKv8yPj7xC03AlwOUFDfRB0kzgOyjrGaVXZSs0sDuji7nOA24FWwH5HKyL1Rb9I\nRPZIifRsVmqmu5feltrGzJYQ/Nq/LDLtRuAZM/sJkAuMiUwfD0wys2sIjgjGAeupWDzw10hwGDAh\n0l+CSCh0TUGkCpFrCv3dPS/sWkSiTaePRESkjI4URESkjI4URESkjEJBRETKKBRERKSMQkFERMoo\nFEREpMz/B6XNWZ8LuMr+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f8ca95d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min validation loss:  1.54750869576\n"
     ]
    }
   ],
   "source": [
    "plot_loss(statlists)\n",
    "print ('min validation loss: ', np.min(statlists[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_bi(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, hidden_size, batchsize):\n",
    "        super(LSTM_bi, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.batchsize = batchsize\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, hidden_layers, bidirectional = True)\n",
    "        self.hidden = self.init_hidden()      \n",
    "        self.linear = nn.Linear(2 * hidden_size, self.output_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(2 * self.hidden_layers, self.batchsize, self.hidden_size)),\n",
    "                Variable(torch.zeros(2 * self.hidden_layers, self.batchsize, self.hidden_size)))\n",
    "    \n",
    "    def forward(self, x):       \n",
    "        lstm_out, self.hidden = self.lstm(x.view(len(x), self.batchsize, -1), self.hidden) \n",
    "        lstm_out = self.linear(lstm_out)\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch: 1       loss:0.904         0.898         \n",
      "model saved.\n",
      "epoch: 2       loss:0.354         0.352         \n",
      "model saved.\n",
      "epoch: 3       loss:0.228         0.230         \n",
      "model saved.\n",
      "epoch: 4       loss:0.179         0.182         \n",
      "model saved.\n",
      "epoch: 5       loss:0.156         0.159         \n",
      "model saved.\n",
      "epoch: 6       loss:0.145         0.149         \n",
      "model saved.\n",
      "epoch: 7       loss:0.135         0.138         \n",
      "model saved.\n",
      "epoch: 8       loss:0.130         0.134         \n",
      "model saved.\n",
      "epoch: 9       loss:0.125         0.129         \n",
      "model saved.\n",
      "epoch: 10       loss:0.121         0.125         \n",
      "model saved.\n",
      "epoch: 11       loss:0.119         0.124         \n",
      "model saved.\n",
      "epoch: 12       loss:0.115         0.119         \n",
      "model saved.\n",
      "epoch: 13       loss:0.114         0.118         \n",
      "model saved.\n",
      "epoch: 14       loss:0.112         0.116         \n",
      "model saved.\n",
      "epoch: 15       loss:0.110         0.114         \n",
      "model saved.\n",
      "epoch: 16       loss:0.109         0.114         \n",
      "model saved.\n",
      "epoch: 17       loss:0.108         0.112         \n",
      "model saved.\n",
      "epoch: 18       loss:0.107         0.111         \n",
      "model saved.\n",
      "epoch: 19       loss:0.105         0.111         \n",
      "model saved.\n",
      "epoch: 20       loss:0.105         0.110         \n",
      "model saved.\n",
      "epoch: 21       loss:0.103         0.109         \n",
      "model saved.\n",
      "epoch: 22       loss:0.101         0.107         \n",
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM_bi(num_chars, 1, 128, batchsize)\n",
    "\n",
    "if use_cuda:\n",
    "    lstm = lstm.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n",
    "num_epoch = 300\n",
    "\n",
    "statlists = training(model = lstm, criterion = loss_function, optimizer = optimizer, \n",
    "                     epochs = num_epoch, dataloaders = dataloaders, step_size = 100, \n",
    "                     gamma = 0.1, use_cuda = use_cuda, checkpoint_ind = 9, \n",
    "                     model_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_ss(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batchsize, method = 'linear'):\n",
    "        super(LSTM_ss, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "        self.batchsize = batchsize\n",
    "        self.sampling_method = method\n",
    "        if self.sampling_method == 'linear':\n",
    "            self.c = 1 / 150000\n",
    "        elif self.sampling_method == 'exponential':\n",
    "            self.c = 0.99995\n",
    "        elif self.sampling_method == 'inverse sigmoid':\n",
    "            self.c = 25000\n",
    "        self.i = 0\n",
    "        self.p = 1\n",
    "        self.cell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.hidden = self.init_hidden()      \n",
    "        self.linear = nn.Linear(hidden_size, self.output_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(self.batchsize, self.hidden_size)),\n",
    "                Variable(torch.zeros(self.batchsize, self.hidden_size)))\n",
    "    \n",
    "    def scheduled_sampling():\n",
    "        if self.sampling_method == 'linear':\n",
    "            self.p = torch.max(0.1, 1 - self.c * self.i)\n",
    "        elif self.sampling_method == 'exponential':\n",
    "            self.p = self.p * self.c\n",
    "        elif self.sampling_method == 'inverse sigmoid':\n",
    "            self.p = self.c / (self.c + np.exp(self.i / self.c))           \n",
    "        self.i += 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out = []\n",
    "        self.scheduled_sampling()\n",
    "        decision = np.random.binomial(n = 1, p = self.p, size = x.size(0))\n",
    "        print ('decision:\\n', decision)\n",
    "        for i in range(x.size(0)):\n",
    "            self.hidden = self.cell(x[i], self.hidden)  \n",
    "            lstm_out.append(self.linear(self.hidden[0]))\n",
    "        lstm_out = torch.stack(lstm_out, 0)\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-45:\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-46:\n",
      "Process Process-47:\n",
      "Process Process-48:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n",
      "torch.Size([4, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b3ce32b42d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                      \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                      model_dir = None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-9475728ffcb2>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, criterion, optimizer, epochs, dataloaders, step_size, gamma, early_stop, use_cuda, checkpoint_ind, model_dir, best_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;31m#             sys.exit(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-909cf2bcb051>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM_ss(num_chars, 128, batchsize)\n",
    "\n",
    "if use_cuda:\n",
    "    lstm = lstm.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n",
    "num_epoch = 300\n",
    "\n",
    "statlists = training(model = lstm, criterion = loss_function, optimizer = optimizer, \n",
    "                     epochs = num_epoch, dataloaders = dataloaders, step_size = 100, \n",
    "                     gamma = 0.1, use_cuda = use_cuda, checkpoint_ind = 1, \n",
    "                     model_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(ran, dist):\n",
    "    r = np.random.random()\n",
    "    sum = 0\n",
    "    for i in range(ran):\n",
    "        sum += dist[i]\n",
    "        if r < sum:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(s):\n",
    "    starter = []\n",
    "    for c in s:\n",
    "        index = char_to_int[c]\n",
    "        one_hot_encoding = torch.zeros(1,num_chars)\n",
    "        one_hot_encoding[0,index] = 1\n",
    "        starter.append(one_hot_encoding)\n",
    "    starter = Variable(torch.stack(starter).type(torch.FloatTensor)).cuda()\n",
    "    return starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(model, starter_str, temp):\n",
    "    starter = wrap(starter_str)\n",
    "    init_hidden = model.init_hidden()\n",
    "    model.hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "    output = model(starter)[-1].view(-1,num_chars)\n",
    "    softmax = torch.nn.Softmax()\n",
    "    output = softmax(output/temp)\n",
    "    predict = simulate(len(output[0]), output[0].data.cpu().numpy())\n",
    "    predict = int_to_char[predict]\n",
    "    starter_str = starter_str + predict\n",
    "    while predict != '%':\n",
    "        output = softmax(model(wrap(predict))[-1].view(-1,num_chars)/temp)\n",
    "        predict = simulate(len(output[0]), output[0].data.cpu().numpy())\n",
    "        predict = int_to_char[predict]\n",
    "        starter_str = starter_str + predict\n",
    "    return starter_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\n",
      "X:67\n",
      "T:Gibs n'uller, The\n",
      "R:jig\n",
      "Z:id:hn-jig-34\n",
      "M:6/8\n",
      "K:D\n",
      "~E3 DFA|\n",
      "~F3 DED|~E3 E3|\n",
      "DBG Bcd|AFD DDB|AFF AFE|FFD DFA|AFD DFA|f2d ede|dBB (3BcB AFA|GAB ~c3|AFD Dgy:|\n",
      "P:Variations:|\n",
      "|:~f3 ^fg|fdf fee|dBc =A2F|1 EDD D2f:|2 ~D3 DEd||\n",
      "~e3 faf|efg dBA|GFE gfe|dfe dcd|cdc d2e|fdd gaa|=~a3 fdB|1 ~D3 D2f||\n",
      "P:Variations:\n",
      "|:~G, AFD|e2c dFE|cAA EDE|1 ~D3 DFA:|2 DDD D3:|\n",
      "|:c2c c2e|gfe deg||\n",
      "|:d2e fdg|faf gfe|faa gag|e2f d2F|GFG ~E3|AFD D2f|ABA ~F3|AdB AFF|AFA d2e|dAd faf|1 gdB AFD:|2 ~B3 BAB:|\n",
      "|:~f3 fdA|BAF gfe|AFD DFA|dBF DFA|BFD AFD:|\n",
      "%\n"
     ]
    }
   ],
   "source": [
    "composed = compose(lstm, \"$\\nX\", 1)\n",
    "print(composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
